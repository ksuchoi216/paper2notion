{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9c5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow \n",
    "\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a373dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_prompt_name': 'papar2notion_system', 'system_prompt_num': 1, 'human_prompt_name': 'papar2notion_human', 'human_prompt_num': 1}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def load_config(config_path=\"./configs/config.yaml\"):\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config = load_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54620702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30001\n"
     ]
    }
   ],
   "source": [
    "url = f'{os.getenv(\"MLFLOW_TRACKING_URI\")}'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "007c9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exists, ID: 1\n",
      "ğŸƒ View run adventurous-yak-763 at: http://localhost:30001/#/experiments/0/runs/4624360a22194923a6339797928ca294\n",
      "ğŸ§ª View experiment at: http://localhost:30001/#/experiments/0\n",
      "âœ… ì—°ê²° ë° ë¡œê·¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "uri = mlflow.get_tracking_uri()\n",
    "\n",
    "# ì‹¤í—˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±\n",
    "exp = mlflow.get_experiment_by_name(\"test-connection\")\n",
    "if exp is None:\n",
    "    exp_id = mlflow.create_experiment(\"test-connection\")\n",
    "    print(\"Created experiment ID:\", exp_id)\n",
    "else:\n",
    "    print(\"Experiment exists, ID:\", exp.experiment_id)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¡œê·¸\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"test_param\", \"ok\")\n",
    "print(\"âœ… ì—°ê²° ë° ë¡œê·¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51f4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.generativeai as genai\n",
    "\n",
    "# # Gemini API í‚¤ ì…ë ¥\n",
    "\n",
    "\n",
    "# def list_gemini_models():\n",
    "#     \"\"\"\n",
    "#     Google Gemini APIë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ ì¶œë ¥\n",
    "#     \"\"\"\n",
    "#     # API í‚¤ë¡œ ì¸ì¦\n",
    "#     genai.configure()\n",
    "\n",
    "#     # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "#     models = genai.list_models()\n",
    "\n",
    "#     print(\"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ëª©ë¡:\")\n",
    "#     for model in models:\n",
    "#         print(f\"- {model.name}\")\n",
    "\n",
    "\n",
    "# # ì‹¤í–‰\n",
    "# if __name__ == \"__main__\":\n",
    "#     list_gemini_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "493b431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def create_llm(model_type: str = \"gemini\", **kwargs):\n",
    "    \"\"\"\n",
    "    LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "\n",
    "    Args:\n",
    "        model_type: \"gemini\" ë˜ëŠ” \"openai\"\n",
    "        **kwargs: ëª¨ë¸ë³„ ì¶”ê°€ ì„¤ì •\n",
    "    \"\"\"\n",
    "    if model_type.lower() == \"gemini\":\n",
    "        print(\"Using Google Gemini model\")\n",
    "        return ChatGoogleGenerativeAI(\n",
    "            model=kwargs.get(\"model\", \"gemini-2.5-pro\"),\n",
    "            temperature=kwargs.get(\"temperature\", 0.0),\n",
    "        )\n",
    "\n",
    "    elif model_type.lower() == \"openai\":\n",
    "        print(\"Using OpenAI model\")\n",
    "        return ChatOpenAI(\n",
    "            model=kwargs.get(\"model\", \"gpt-4o-mini\"),\n",
    "            temperature=kwargs.get(\"temperature\", 0.0),\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5789d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Google Gemini model\n"
     ]
    }
   ],
   "source": [
    "llm = create_llm(\"gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: gemini\n",
      "System Prompt 4:\n",
      "## System\n",
      "ë„ˆëŠ” ì„¤ëª…ì„ ì¹œì ˆí•˜ê²Œ ì˜í•´ì£¼ëŠ” êµìˆ˜ì•¼. \n",
      "ë…¼ë¬¸ì„ ì•„ë˜ì™€ ê°™ì´ ìš”ì•½í•´ì„œ ë°°ê²½ì§€ì‹ì´ ì—†ëŠ” í•™ìƒë“¤ì—ê²Œ ì„¤ëª…í•œë‹¤ê³  ìƒê°í•´.\n",
      "ë…¼ë¬¸ì„ ì½ê¸° ì „ ë¯¸ë¦¬ ë°°ê²½ì§€ì‹ì„ ì–»ì„ ìˆ˜ ìˆëŠ” ìš”ì•½ì„ ë§Œë“¤ì–´ì¤˜.\n",
      "ë°˜ë“œì‹œ content ì£¼ìš” ë‚´ìš© ì‚¬ì´ì—ëŠ” \"---\"ì„ ì‚½ì…í•´ì„œ ëª…í™•íˆ êµ¬ë¶„í•´ì¤˜.\n",
      "\n",
      "## Content ì£¼ìš” ë‚´ìš©\n",
      "ì•„ë˜ì™€ ê°™ì´ 9ê°€ì§€ ë¶€ë¶„ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\n",
      "1. ì—°êµ¬ ë™ê¸°(ì™œ ì´ ì—°êµ¬ë¥¼ í–ˆëŠ”ì§€)ì™€ ë…¼ë¬¸ ì œëª©ì˜ ì´ìœ .\n",
      "2. ìš”ì•½. ì´ ë¶€ë¶„ì€ Abstractê³¼ Conclusion ë¶€ë¶„ì˜ ë‚´ìš©ì„ ìš”ì•½.\n",
      "    ìš”ì•½í•  ë•ŒëŠ” ì™œ ì´ ì—°êµ¬ë¥¼ í–ˆëŠ”ì§€(Why), ê·¸ë˜ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ ì œì‹œí–ˆëŠ”ì§€(What), ì–´ë–»ê²Œ ì ìš© í–ˆëŠ”ì§€(How)ë¡œ ì„¤ëª…í•´ì¤˜.\n",
      "3. ë…¼ë¬¸ì˜ methodology. ì§ê´€ì ì¸ ì˜ˆì‹œë¥¼ í†µí•´ ìì„¸í•œ ì„¤ëª… ë¶€íƒí•´. \n",
      "4. ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„° ì…‹(dataset)ê³¼ í‰ê°€ ì§€í‘œ(evaluation metric)ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\n",
      "    - ë°ì´í„° ì…‹ê³¼ í‰ê°€ì§€í‘œëŠ” ë³¸ë¬¸ ë‚´ìš©ì„ ì „ë¶€ ì•Œë ¤ì¤˜.\n",
      "5. ê²°ê³¼ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•´ì¤˜.\n",
      "6. ë…¼ë¬¸ì´ ì œì‹œí•œ ë°©ë²•ì˜ ì¥ë‹¨ì .\n",
      "7. ì´ ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¨ ì¶”ì²œí•  ë§Œí•œ References. ì˜ˆë¥¼ ë“¤ì–´, Referenceë¥¼ ì§ì ‘ì ìœ¼ë¡œ ë°œì „ ì‹œì¼œ ì—°êµ¬í•œ ë…¼ë¬¸ì´ë©´, referenceë¥¼ ë¶€íƒí•´.\n",
      "8. ì•„ë˜ ì •ë³´ë„ ê°œì¡°ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ê° ìš”ì†Œë§ˆë‹¤ ë³µì‚¬í•˜ê¸° í¸í•˜ê²Œ ì •ë¦¬í•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´, title ë”°ë¡œ(titleë§Œ), year ë”°ë¡œ(YYYY ìˆ«ìë§Œ), citation ë”°ë¡œ(ìˆ«ìë§Œ), tags ë”°ë¡œ(tag1, tag2, tag3, tag4)\n",
      "- title: ë…¼ë¬¸ ì´ë¦„\n",
      "- year: ë°œí–‰ë…„ë„\n",
      "- citation: ì¸ìš©ìˆ˜\n",
      "- tags: ë…¼ë¬¸ì„ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ í•„ìš”í•œ í‚¤ì›Œë“œë“¤, í° ì¹´í…Œê³ ë¦¬ ë° ì„¸ë¶€ ê¸°ìˆ ì˜ í‚¤ì›Œë“œê°€ í•„ìš”í•¨.\n",
      "9. short_summary: ìµœì¢…ì ìœ¼ë¡œ ì „ì²´ì ì¸ ë‚´ìš©ì„ í•µì‹¬ì ì¸ 2ê°œ ë¬¸ì¥ì„ ê°œì¡°ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. ë°˜ë“œì‹œ ì²œì²œíˆ ìƒê°í•´ë³´ê³  ì°¨ê·¼ì°¨ê·¼ ìƒê°í•´ì„œ í•µì‹¬ì ì¸ ë‹¨ì–´ì™€ í‘œí˜„ìœ¼ë¡œ ë¶€íƒí•´. ì œì¼ ì¤‘ìš”í•œ ë¶€ë¶„ì´ì•¼. ë³µì‚¬í•˜ê¸° í¸í•˜ê²Œ ì •ë¦¬í•´ì¤˜.\n",
      "Human Prompt 2:\n",
      "ì•„ë˜ ë§í¬ì˜ ë…¼ë¬¸ì„ ìš”ì•½í•´ì¤˜. ë°˜ë“œì‹œ ì•„ë˜ instructionsì„ ì§€ì¼œì„œ ëŒ€ë‹µí•´ì¤˜. ë…¼ë¬¸ì„ ì²œì²œíˆ ì´í•´í•˜ê³  ëŒ€ë‹µí•´ì¤˜.\n",
      "<link>\n",
      "{paper_url}\n",
      "</link>\n",
      "\n",
      "<instructions>\n",
      "ì•„ë˜ì™€ ê°™ì€ ì§€ì‹œì‚¬í•­ì„ ì§€ì¼œì£¼ë©° ì‘ì„±í•´ì¤˜.\n",
      "- ê° ë¶€ë¶„ì€ ìµœëŒ€ 8ë¬¸ì¥ê¹Œì§€ ë§Œë“¤ì–´ì¤˜. ë‹¨, ë„ˆë¬´ ì§§ìœ¼ë©´ ì•ˆë¼. ë‹¨, methodology ë¶€ë¶„ì€ ìì„¸í•˜ê³  ê¸¸ê²Œ ì„¤ëª…í•´ì¤˜.\n",
      "- ê¸°ìˆ ì  ì¤‘ìš” ì‚¬í•­ì€ ì²´ê³„ì ìœ¼ë¡œ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.\n",
      "- ì˜ ëª¨ë¥´ê² ë‹¤ë©´, ì˜ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•´ì¤˜.\n",
      "- content ì£¼ìš” ë‚´ìš© ì‚¬ì´ì—ëŠ” '---'ë¡œ êµ¬ë¶„í•´ì¤˜.\n",
      "- í•µì‹¬ 2ë¬¸ì¥ ìš”ì•½ì€ ê°œì¡°ì‹ìœ¼ë¡œ ë¶€íƒí•´. \n",
      "</instructions>\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import datetime\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    title: str = Field(..., description=\"ë…¼ë¬¸ì˜ ì œëª©\")\n",
    "    year: int = Field(..., description=\"ë…¼ë¬¸ì˜ ì¶œíŒ ì—°ë„\")\n",
    "    citation: int = Field(..., description=\"ë…¼ë¬¸ì˜ ì¸ìš© ìˆ˜\")\n",
    "    short_summary: str = Field(..., description=\"ë…¼ë¬¸ì˜ ìš”ì•½\")\n",
    "    tags: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"ë…¼ë¬¸ì˜ í‚¤ì›Œë“œ. í‚¤ì›Œë“œëŠ” ë…¼ë¬¸ì„ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì •ë³´. ëŒ€ë¶„ë¥˜ë¶€í„° ë””í…Œì¼í•œ í‚¤ì›Œë“œê¹Œì§€ í¬í•¨. ìµœëŒ€ 4ê°œ.\",\n",
    "    )\n",
    "    content: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"ë…¼ë¬¸ì˜ ì£¼ìš” ë‚´ìš©. Contentì˜ ì£¼ìš” ë‚´ìš©ìœ¼ë¡œ system promptì—ì„œ ì§€ì‹œí•œ ë‚´ìš©ì˜ ë‹µë³€ì…ë‹ˆë‹¤.\",\n",
    "    )\n",
    "    paper_url: str = Field(..., description=\"ë…¼ë¬¸ì˜ URL\")\n",
    "\n",
    "\n",
    "class LLMChain:\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_name: str = \"paper2notion\",\n",
    "        model_type: str = \"gemini\",\n",
    "        prompt_name: str = \"paper2notion\",\n",
    "        system_prompt_num: int = 1,\n",
    "        human_prompt_num: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        print(f\"model type: {model_type}\")\n",
    "        self.llm = self.create_llm(model_type, **kwargs)\n",
    "        self.system_prompt, self.human_prompt = self.get_prompt(\n",
    "            prompt_name=prompt_name,\n",
    "            system_prompt_num=system_prompt_num,\n",
    "            human_prompt_num=human_prompt_num,\n",
    "        )\n",
    "        self.experiment_id, self.run_name = self.create_run_name(\n",
    "            experiment_name, model_type, system_prompt_num, human_prompt_num\n",
    "        )\n",
    "        self.__setup__(self.llm, self.system_prompt, self.human_prompt)\n",
    "\n",
    "    def create_run_name(\n",
    "        self, experiment_name, model_type, system_prompt_num, human_prompt_num\n",
    "    ):\n",
    "        if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "            experiment_id = experiment.experiment_id\n",
    "        else:\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        run_name = datetime.datetime.now().strftime(\"%m%d-%H%M%S\")\n",
    "        run_name += f\"_{model_type}_s{system_prompt_num}_h{human_prompt_num}\"\n",
    "        return experiment_id, run_name\n",
    "\n",
    "    def create_llm(self, model_type: str = \"gemini\", **kwargs):\n",
    "        if model_type.lower() == \"gemini\":\n",
    "            return ChatGoogleGenerativeAI(\n",
    "                model=kwargs.get(\"model\", \"gemini-2.5-pro\"),\n",
    "                temperature=kwargs.get(\"temperature\", 0.0),\n",
    "            )\n",
    "        elif model_type.lower() == \"openai\":\n",
    "            return ChatOpenAI(\n",
    "                model=kwargs.get(\"model\", \"gpt-4o-mini\"),\n",
    "                temperature=kwargs.get(\"temperature\", 0.0),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}\")\n",
    "\n",
    "    def get_prompt(self, prompt_name, system_prompt_num=1, human_prompt_num=1):\n",
    "        system_prompt = mlflow.genai.load_prompt(  # type: ignore\n",
    "            f\"prompts:/paper2notion_system/{system_prompt_num}\"\n",
    "        ).to_single_brace_format()\n",
    "        human_prompt = mlflow.genai.load_prompt(  # type: ignore\n",
    "            f\"prompts:/paper2notion_human/{human_prompt_num}\"\n",
    "        ).to_single_brace_format()\n",
    "\n",
    "        print(f\"System Prompt {system_prompt_num}:\")\n",
    "        print(system_prompt)\n",
    "\n",
    "        print(f\"Human Prompt {human_prompt_num}:\")\n",
    "        print(human_prompt)\n",
    "\n",
    "        return system_prompt, human_prompt\n",
    "\n",
    "    def __setup__(self, llm, system_prompt, human_prompt):\n",
    "        parser = PydanticOutputParser(pydantic_object=Output)\n",
    "        format_instructions = (\n",
    "            parser.get_format_instructions().replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", system_prompt), (\"human\", human_prompt + format_instructions)]\n",
    "        )\n",
    "\n",
    "        self.chain = prompt | llm | parser\n",
    "\n",
    "    def run(self, paper_url):\n",
    "        input_dict = {\"paper_url\": paper_url}\n",
    "\n",
    "        with mlflow.start_run(experiment_id=self.experiment_id, run_name=self.run_name):\n",
    "            mlflow.log_param(\"paper_url\", paper_url)\n",
    "            output = self.chain.invoke(input_dict)\n",
    "            mlflow.log_params(output.dict())\n",
    "            return output\n",
    "\n",
    "\n",
    "chain = LLMChain(\n",
    "    experiment_name=\"paper2notion\",\n",
    "    model_type=\"gemini\",\n",
    "    system_prompt_num=4,\n",
    "    human_prompt_num=2,\n",
    ")\n",
    "\n",
    "output = chain.run(\"https://arxiv.org/pdf/2305.07895\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca7c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1. ì—°êµ¬ ë™ê¸°(ì™œ ì´ ì—°êµ¬ë¥¼ í–ˆëŠ”ì§€)ì™€ ë…¼ë¬¸ ì œëª©ì˜ ì´ìœ .\\nì•ˆë…•í•˜ì„¸ìš”, í•™ìƒ ì—¬ëŸ¬ë¶„. ì˜¤ëŠ˜ ë‹¤ë£° ë…¼ë¬¸ì€ LLM(ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸)ì´ ì–´ë–»ê²Œ ìŠ¤ìŠ¤ë¡œ ë” ë˜‘ë˜‘í•´ì§ˆ ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì—°êµ¬ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ê¸€ì„ ì“¸ ë•Œ ì´ˆê³ ë¥¼ ì‘ì„±í•˜ê³ , ë‹¤ì‹œ ì½ì–´ë³´ë©° ì–´ìƒ‰í•œ ë¶€ë¶„ì„ ê³ ì¹˜ëŠ” ê²ƒì²˜ëŸ¼, LLMë„ í•œ ë²ˆì— ì™„ë²½í•œ ê²°ê³¼ë¬¼ì„ ë‚´ë†“ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë°”ë¡œ ì´ ì§€ì ì—ì„œ ì¶œë°œí•©ë‹ˆë‹¤. LLMì´ ìƒì„±í•œ ê²°ê³¼ë¬¼ì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•˜ê³ , ê·¸ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë” ë‚˜ì€ ê²°ê³¼ë¬¼ì„ ë§Œë“¤ë„ë¡ í•  ìˆ˜ëŠ” ì—†ì„ê¹Œ? ë¼ëŠ” ì§ˆë¬¸ì´ ì—°êµ¬ì˜ ë™ê¸°ì…ë‹ˆë‹¤. ë…¼ë¬¸ ì œëª©ì¸ 'Self-Refine'ì€ ì´ ê³¼ì •ì„ ì•„ì£¼ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ(Self) ìì‹ ì˜ ê²°ê³¼ë¬¼ì„ ê°œì„ (Refine)í•œë‹¤ëŠ” ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆì£ . ì™¸ë¶€ì˜ ë„ì›€ ì—†ì´ ìŠ¤ìŠ¤ë¡œ ë°œì „í•˜ëŠ” ë˜‘ë˜‘í•œ ëª¨ë¸ì„ ë§Œë“¤ê³ ì í•œ ê²ƒì…ë‹ˆë‹¤.\", \"2. ìš”ì•½. ì´ ë¶€ë¶„ì€ Abstractê³¼ Conclusion ë¶€ë¶„ì˜ ë‚´ìš©ì„ ìš”ì•½.\\nì´ ë…¼ë¬¸ì„ 'ì™œ, ë¬´ì—‡ì„, ì–´ë–»ê²Œ'ë¡œ ìš”ì•½í•´ ë³´ê² ìŠµë‹ˆë‹¤. (Why) ì™œ ì´ ì—°êµ¬ë¥¼ í–ˆì„ê¹Œìš”? ì•ì„œ ë§í–ˆë“¯, GPTì™€ ê°™ì€ LLMì€ í•œ ë²ˆì˜ ì‹œë„ë¡œëŠ” ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•´ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¯¸í¡í•œ ë‹µë³€ì„ ë‚´ë†“ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. (What) ê·¸ë˜ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ ì œì‹œí–ˆë‚˜ìš”? ì—°êµ¬ì§„ì€ 'Self-Refine'ì´ë¼ëŠ” ê°„ë‹¨í•˜ì§€ë§Œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” LLMì´ ìì‹ ì˜ ê²°ê³¼ë¬¼ì„ ë¹„í‰í•˜ê³ , ê·¸ ë¹„í‰ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ ê²°ê³¼ë¬¼ì„ ìˆ˜ì •í•´ ë‚˜ê°€ëŠ” ë°˜ë³µì ì¸ ê³¼ì •ì…ë‹ˆë‹¤. (How) ì–´ë–»ê²Œ ì ìš©í–ˆì„ê¹Œìš”? ë³„ë„ì˜ ëª¨ë¸ í›ˆë ¨ì´ë‚˜ ë°ì´í„° ì—†ì´, ì´ë¯¸ ì¡´ì¬í•˜ëŠ” LLM(ì˜ˆ: GPT-3.5, GPT-4)ì—ê²Œ íŠ¹ì • ì—­í• ì„ ë¶€ì—¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸(ì§€ì‹œì–´)ë§Œìœ¼ë¡œ ì´ ê³¼ì •ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì½”ë”©, ì‘ë¬¸, ìˆ˜í•™ ë¬¸ì œ í’€ì´ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì— ì ìš©í•˜ì—¬ Self-Refineì´ ê¸°ì¡´ì˜ ë‹¨ì¼ ë‹µë³€ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.\", '3. ë…¼ë¬¸ì˜ methodology. ì§ê´€ì ì¸ ì˜ˆì‹œë¥¼ í†µí•´ ìì„¸í•œ ì„¤ëª… ë¶€íƒí•´.\\nSelf-Refineì˜ ë°©ë²•ë¡ ì€ ìš°ë¦¬ê°€ ê³¼ì œë¥¼ í•˜ëŠ” ê³¼ì •ê³¼ ì•„ì£¼ í¡ì‚¬í•´ì„œ ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ì´ 3ë‹¨ê³„ì˜ ë°˜ë³µ ê³¼ì •ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\\n\\n1ë‹¨ê³„: **ì´ˆì•ˆ ìƒì„± (Initial Output)**\\në¨¼ì €, ëª¨ë¸ì—ê²Œ ê³¼ì œë¥¼ ì¤ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \\'ì½”ë¼ë¦¬ë¥¼ ëƒ‰ì¥ê³ ì— ë„£ëŠ” ë²•ì„ ì°½ì˜ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\\'ë¼ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ëŸ¼ ëª¨ë¸ì€ ì²« ë²ˆì§¸ ë‹µë³€, ì¦‰ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. \"1. ëƒ‰ì¥ê³  ë¬¸ì„ ì—°ë‹¤. 2. ì½”ë¼ë¦¬ë¥¼ ë„£ëŠ”ë‹¤. 3. ëƒ‰ì¥ê³  ë¬¸ì„ ë‹«ëŠ”ë‹¤.\" ì™€ ê°™ì€ ê³ ì „ì ì¸ ë‹µë³€ì„ ë‚´ë†“ì•˜ë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤.\\n\\n2ë‹¨ê³„: **ìê°€ í”¼ë“œë°± (Self-Feedback)**\\nì´ì œ ëª¨ë¸ì—ê²Œ ì—­í• ì„ ë°”ê¿”ì„œ ë¹„í‰ê°€ê°€ ë˜ì–´ë³´ë¼ê³  ì§€ì‹œí•©ë‹ˆë‹¤. ë°©ê¸ˆ ìƒì„±í•œ ì´ˆì•ˆì„ ë³´ì—¬ì£¼ë©° \"ì´ ë‹µë³€ì˜ ë¬¸ì œì ì€ ë¬´ì—‡ì´ê³ , ì–´ë–»ê²Œ ê°œì„ í•˜ë©´ ë” ì°½ì˜ì ì¼ê¹Œ?\"ë¼ê³  ë¬»ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ëª¨ë¸ì€ ìŠ¤ìŠ¤ë¡œë¥¼ í‰ê°€í•˜ë©° \"ì´ ë‹µë³€ì€ ë„ˆë¬´ ê³ ì „ì ì´ê³  ì¬ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì½”ë¼ë¦¬ì˜ í¬ê¸°ë‚˜ ëƒ‰ì¥ê³ ì˜ ì¢…ë¥˜ ê°™ì€ ë¬¼ë¦¬ì  ì œì•½ì„ ë¬´ì‹œí•˜ëŠ” ìƒìƒë ¥ì´ ë” í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \\'ì½”ë¼ë¦¬ë¥¼ ë°ì´í„°í™”í•´ì„œ ì´ë©”ì¼ë¡œ ë³´ë‚¸ ë’¤ ëƒ‰ì¥ê³  ëª¨ì–‘ì˜ USBì— ì €ì¥í•œë‹¤\\' ì™€ ê°™ì€ ì•„ì´ë””ì–´ë¥¼ ì¶”ê°€í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\" ë¼ëŠ” í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.\\n\\n3ë‹¨ê³„: **ê°œì„  (Refine)**\\në§ˆì§€ë§‰ìœ¼ë¡œ, ëª¨ë¸ì—ê²Œ ì›ë˜ì˜ ê³¼ì œì™€ ì´ˆì•ˆ, ê·¸ë¦¬ê³  ë°©ê¸ˆ ìƒì„±í•œ í”¼ë“œë°±ì„ ëª¨ë‘ í•¨ê»˜ ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë ‡ê²Œ ì§€ì‹œí•©ë‹ˆë‹¤. \"ì´ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ì›ë˜ì˜ ë‹µë³€ì„ ë” ì°½ì˜ì ìœ¼ë¡œ ìˆ˜ì •í•´ì¤˜.\" ê·¸ëŸ¬ë©´ ëª¨ë¸ì€ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ \"ì½”ë¼ë¦¬ë¥¼ \\'ì½”ë¼ë¦¬.zip\\' íŒŒì¼ë¡œ ì••ì¶•í•œ ë’¤, í´ë¼ìš°ë“œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ìŠ¤ë§ˆíŠ¸ ëƒ‰ì¥ê³ ì˜ ì•± ìŠ¤í† ì–´ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„¤ì¹˜í•˜ë©´ ë©ë‹ˆë‹¤.\" ì™€ ê°™ì´ í›¨ì”¬ ë” ì°½ì˜ì ì´ê³  ê°œì„ ëœ ê²°ê³¼ë¬¼ì„ ë‚´ë†“ê²Œ ë©ë‹ˆë‹¤.\\n\\nì´ 3ë‹¨ê³„ ê³¼ì •ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ë©´(Iteration), ê²°ê³¼ë¬¼ì€ ì ì  ë” ì •êµí•˜ê³  ì™„ì„±ë„ ë†’ê²Œ ë°œì „í•©ë‹ˆë‹¤. ì´ ëª¨ë“  ê³¼ì •ì´ ì™¸ë¶€ì˜ ê°œì… ì—†ì´ ì˜¤ì§ ëª¨ë¸ ìŠ¤ìŠ¤ë¡œì˜ ëŠ¥ë ¥ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤ëŠ” ì ì´ ì´ ë°©ë²•ë¡ ì˜ í•µì‹¬ì…ë‹ˆë‹¤.', '4. ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„° ì…‹(dataset)ê³¼ í‰ê°€ ì§€í‘œ(evaluation metric)ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.\\nì´ ì—°êµ¬ëŠ” Self-Refineì˜ íš¨ê³¼ë¥¼ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ê²€ì¦í•˜ê¸° ìœ„í•´ ì´ 7ê°œì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\\n\\n**ë°ì´í„°ì…‹(Datasets):**\\n*   **ì½”ë“œ ìƒì„±/ê°œì„  (Code Generation/Improvement):** `HumanEval-Plus`, `MBPP-Plus` - íŒŒì´ì¬ ì½”ë”© ë¬¸ì œë¥¼ í‘¸ëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n*   **ìˆ˜í•™ ì¶”ë¡  (Mathematical Reasoning):** `GSM8K` - ì´ˆë“±í•™êµ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ì‘ìš© ë¬¸ì œì…ë‹ˆë‹¤.\\n*   **ìƒì‹ ê¸°ë°˜ ë¬¸ì¥ ìƒì„± (Commonsense Generation):** `CommonGen` - ì£¼ì–´ì§„ ëª‡ ê°œì˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•´ ìƒì‹ì ì¸ ë¬¸ì¥ì„ ë§Œë“œëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n*   **ì‚¬íšŒì  ìƒì‹ ì¶”ë¡  (Social Commonsense Reasoning):** `SocialIQA` - ì‚¬íšŒì  ìƒí™©ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n*   **ëŒ€í™” ì‘ë‹µ ìƒì„± (Dialogue Response Generation):** `Topical-Chat` - ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\\n*   **ë‘ë¬¸ìì–´ ìƒì„± (Acronym Generation):** `BIG-Bench`ì˜ ì¼ë¶€ë¡œ, ì£¼ì–´ì§„ êµ¬ì ˆì— ë§ëŠ” ë‘ë¬¸ìì–´ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì œì…ë‹ˆë‹¤.\\n\\n**í‰ê°€ ì§€í‘œ(Evaluation Metrics):**\\n*   ì½”ë“œ ìƒì„± ë¬¸ì œ(`HumanEval-Plus`, `MBPP-Plus`)ì—ì„œëŠ” ìƒì„±ëœ ì½”ë“œê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ í†µê³¼í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì¸¡ì •í•˜ëŠ” `pass@1`ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\\n*   ìˆ˜í•™ ë¬¸ì œ(`GSM8K`)ì™€ ì‚¬íšŒì  ìƒì‹ ì¶”ë¡ (`SocialIQA`)ì—ì„œëŠ” ì •ë‹µì„ ë§í˜”ëŠ”ì§€ `ì •í™•ë„(Accuracy)`ë¥¼ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤.\\n*   ë‘ë¬¸ìì–´ ìƒì„±ì—ì„œëŠ” ìƒì„±ëœ ë‹¨ì–´ê°€ ì •ë‹µê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ `Exact Match(EM)`ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.\\n*   ë¬¸ì¥ ìƒì„±(`CommonGen`)ì—ì„œëŠ” ìƒì„±ëœ ë¬¸ì¥ì´ ì–¼ë§ˆë‚˜ ìì—°ìŠ¤ëŸ¬ìš´ì§€ë¥¼ í‰ê°€í•˜ëŠ” `BLEU`, `SPICE`, `CIDEr` ê°™ì€ ìë™ í‰ê°€ ì§€í‘œë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\\n*   ëŒ€í™” ì‘ë‹µ(`Topical-Chat`)ê³¼ ê°™ì´ ì •ë‹µì´ ì •í•´ì ¸ ìˆì§€ ì•Šì€ ê³¼ì œì—ì„œëŠ”, GPT-4ë¥¼ í‰ê°€ìë¡œ í™œìš©í•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆ(ì¼ê´€ì„±, í¥ë¯¸ë„ ë“±)ì„ 1~5ì  ì²™ë„ë¡œ í‰ê°€í•˜ëŠ” ë°©ì‹ì„ ë„ì…í–ˆê³ , ì‚¬ëŒë„ ì§ì ‘ í‰ê°€ì— ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.', '5. ê²°ê³¼ì— ëŒ€í•´ ê°„ëµíˆ ì„¤ëª…í•´ì¤˜.\\nê²°ê³¼ëŠ” ë§¤ìš° ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤. Self-Refineì„ ì ìš©í–ˆì„ ë•Œ, GPT-3.5ì™€ GPT-4 ê°™ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì‹¤í—˜ì— ì‚¬ìš©ëœ 7ê°œ ê³¼ì œ ëª¨ë‘ì—ì„œ ëˆˆì— ë„ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ê¸°ì¡´ì˜ í•œ ë²ˆì— ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹(one-shot)ì— ë¹„í•´ ì ˆëŒ€ ì„±ëŠ¥ì´ í‰ê·  20% ê°€ê¹Œì´ ì˜¤ë¥´ëŠ” í° í­ì˜ ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì¬ë¯¸ìˆëŠ” ì ì€, ì´ëŸ¬í•œ ìê¸° ê°œì„  ëŠ¥ë ¥ì€ ëª¨ë¸ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ë” ì˜ ë°œí˜„ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì‘ì€ ëª¨ë¸ë“¤ì€ ìœ ìš©í•œ í”¼ë“œë°±ì„ ìƒì„±í•˜ì§€ ëª»í•´ ì„±ëŠ¥ í–¥ìƒì´ ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ê°œì„  ê³¼ì •ì„ ë°˜ë³µí• ìˆ˜ë¡ ì„±ëŠ¥ì´ ê³„ì† ì˜¤ë¥´ë‹¤ê°€ íŠ¹ì • ì§€ì ì—ì„œ ìˆ˜ë ´í•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì—¬ëŸ¬ ë²ˆ ê³ ì³ ì“¸ìˆ˜ë¡ ê¸€ì´ ì¢‹ì•„ì§€ëŠ” ê²ƒê³¼ ê°™ì€ ì´ì¹˜ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', \"6. ë…¼ë¬¸ì´ ì œì‹œí•œ ë°©ë²•ì˜ ì¥ë‹¨ì .\\nì´ ë°©ë²•ì€ ì—¬ëŸ¬ ì¥ì ì´ ìˆì§€ë§Œ, ëª…í™•í•œ í•œê³„ë„ ì¡´ì¬í•©ë‹ˆë‹¤.\\n\\n**ì¥ì :**\\n*   **ë²”ìš©ì„±:** ë³„ë„ì˜ ëª¨ë¸ í›ˆë ¨ ì—†ì´ í”„ë¡¬í”„íŠ¸ ì¡°ì‘ë§Œìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥í•´ ì–´ë–¤ LLMì—ë„ ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n*   **ë‹¤ì¬ë‹¤ëŠ¥í•¨:** ì½”ë”©, ì‘ë¬¸, ì¶”ë¡  ë“± íŠ¹ì • ë¶„ì•¼ì— êµ­í•œë˜ì§€ ì•Šê³  ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê³¼ì œì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\\n*   **ì„±ëŠ¥ í–¥ìƒ:** ì¶”ê°€ ë°ì´í„° ì—†ì´ ëª¨ë¸ ìì²´ì˜ ì ì¬ë ¥ì„ ëŒì–´ë‚´ ê²°ê³¼ë¬¼ì˜ ì§ˆì„ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n*   **í•´ì„ ê°€ëŠ¥ì„±:** 'í”¼ë“œë°±' ë‹¨ê³„ ë•ë¶„ì— ëª¨ë¸ì´ ì™œ ê·¸ë ‡ê²Œ ë‹µë³€ì„ ìˆ˜ì •í–ˆëŠ”ì§€ ê·¸ ì´ìœ ë¥¼ ì•Œ ìˆ˜ ìˆì–´ ê³¼ì •ì´ íˆ¬ëª…í•©ë‹ˆë‹¤.\\n\\n**ë‹¨ì :**\\n*   **ë¹„ìš© ë° ì‹œê°„ ì¦ê°€:** í”¼ë“œë°±ê³¼ ê°œì„ ì„ ìœ„í•´ ëª¨ë¸ì„ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•´ì•¼ í•˜ë¯€ë¡œ, ì‹œê°„ê³¼ ë¹„ìš©(API ì‚¬ìš©ë£Œ)ì´ ëª‡ ë°°ë¡œ ì¦ê°€í•©ë‹ˆë‹¤.\\n*   **ëª¨ë¸ ì˜ì¡´ì„±:** ëª¨ë¸ ìì²´ê°€ ë˜‘ë˜‘í•´ì•¼ íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ì€ ìŠ¤ìŠ¤ë¡œ ìœ ì˜ë¯¸í•œ í”¼ë“œë°±ì„ ë§Œë“¤ì§€ ëª»í•´ ì´ ë°©ë²•ì´ ì†Œìš©ì—†ìŠµë‹ˆë‹¤.\\n*   **ì§€ì‹ì˜ í•œê³„:** ëª¨ë¸ì´ ì²˜ìŒë¶€í„° ì˜ëª» ì•Œê³  ìˆëŠ” ì‚¬ì‹¤ì€ ìŠ¤ìŠ¤ë¡œ êµì •í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì˜¤íˆë ¤ ì˜ëª»ëœ ë¯¿ìŒì„ í”¼ë“œë°± ê³¼ì •ì—ì„œ ë” ê°•í™”í•  ìœ„í—˜ë„ ìˆìŠµë‹ˆë‹¤.\", \"7. ì´ ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¨ ì¶”ì²œí•  ë§Œí•œ References.\\nì´ ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´ëŠ” LLMì—ê²Œ ìƒê°ì˜ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì œì‹œí•˜ê²Œ í•˜ì—¬ ì¶”ë¡  ëŠ¥ë ¥ì„ ë†’ì´ëŠ” ì—°êµ¬ë“¤ë¡œë¶€í„° í° ì˜í–¥ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê·¸ì¤‘ì—ì„œë„ ê°€ì¥ ëŒ€í‘œì ì¸ ì„ í–‰ ì—°êµ¬ëŠ” ë°”ë¡œ 'Chain-of-Thought (CoT) Prompting'ì…ë‹ˆë‹¤. CoTëŠ” ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•´ 'ì°¨ê·¼ì°¨ê·¼ ìƒê°í•´ ë³´ì(Let's think step by step)'ë¼ëŠ” ë¬¸êµ¬ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ ëª¨ë¸ì´ í’€ì´ ê³¼ì •ì„ ìƒì„±í•˜ê²Œ í•˜ì—¬ ì •ë‹µë¥ ì„ ë†’ì¸ íšê¸°ì ì¸ ì—°êµ¬ì…ë‹ˆë‹¤. Self-Refineì€ ì´ëŸ¬í•œ 'ìƒê°ì˜ ê³¼ì •'ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ê·¸ ê³¼ì •ì„ 'í‰ê°€'í•˜ê³  'ê°œì„ 'í•˜ëŠ” ë‹¨ê³„ê¹Œì§€ í™•ì¥í–ˆë‹¤ëŠ” ì ì—ì„œ CoTì˜ ì§ê³„ í›„ì†ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ì´í•´í•˜ëŠ” ë° ìˆì–´ ì•„ë˜ ë…¼ë¬¸ì„ í•¨ê»˜ ì½ì–´ë³´ì‹œê¸¸ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤.\\n\\n*   **Wei, J., et al. (2022). Chain-of-thought prompting elicits reasoning in large language models.** ì´ ë…¼ë¬¸ì€ CoT ê°œë…ì„ ì²˜ìŒìœ¼ë¡œ ì œì‹œí•˜ì—¬ LLM í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë¶„ì•¼ì— í° ë°˜í–¥ì„ ì¼ìœ¼ì¼°ìŠµë‹ˆë‹¤.\", '8. ì•„ë˜ ì •ë³´ë„ ê°œì¡°ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.\\n- title: Self-Refine: Iterative Refinement with Self-Feedback\\n- year: 2023\\n- citation: 599\\n- tags: Large Language Model, Prompt Engineering, In-Context Learning, Iterative Refinement', \"9. short_summary: ìµœì¢…ì ìœ¼ë¡œ ì „ì²´ì ì¸ ë‚´ìš©ì„ í•µì‹¬ì ì¸ 2ê°œ ë¬¸ì¥ì„ ê°œì¡°ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.\\n- LLMì´ ìƒì„±í•œ ì´ˆì•ˆì„ ìŠ¤ìŠ¤ë¡œ í”¼ë“œë°±í•˜ê³  ìˆ˜ì •í•˜ëŠ” 'Self-Refine' í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ ë°˜ë³µì ìœ¼ë¡œ í–¥ìƒì‹œí‚´.\\n- ì´ ë°©ë²•ì€ ì—¬ëŸ¬ ë²ˆì˜ API í˜¸ì¶œë¡œ ë¹„ìš©ê³¼ ì‹œê°„ì´ ì¦ê°€í•˜ëŠ” ë‹¨ì ì´ ìˆì§€ë§Œ, ë³„ë„ì˜ í›ˆë ¨ ë°ì´í„° ì—†ì´ë„ ëª¨ë¸ì˜ ë‚´ì¬ëœ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì„.\"]\n",
      "9\n",
      "<class 'list'>\n",
      "âœ… í˜ì´ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "{'object': 'page', 'id': '2283a61e-46e5-815b-beba-c967e29ac7da', 'created_time': '2025-07-06T11:39:00.000Z', 'last_edited_time': '2025-07-06T11:39:00.000Z', 'created_by': {'object': 'user', 'id': '3de7c8f9-758d-465d-822e-3ca39da44e71'}, 'last_edited_by': {'object': 'user', 'id': '3de7c8f9-758d-465d-822e-3ca39da44e71'}, 'cover': None, 'icon': None, 'parent': {'type': 'database_id', 'database_id': '1763a61e-46e5-80c0-9b2d-c590f37618fd'}, 'archived': False, 'in_trash': False, 'properties': {'Citation': {'id': '%3AYEl', 'type': 'number', 'number': 599}, 'Done': {'id': 'JC%7Bo', 'type': 'button', 'button': {}}, 'URL': {'id': 'KGeq', 'type': 'url', 'url': 'https://arxiv.org/pdf/2305.07895'}, 'Created time': {'id': 'ZetJ', 'type': 'created_time', 'created_time': '2025-07-06T11:39:00.000Z'}, 'Year': {'id': '%5B%5CRf', 'type': 'number', 'number': 2023}, 'Summary': {'id': '%5Ew%5CF', 'type': 'rich_text', 'rich_text': [{'type': 'text', 'text': {'content': \"- LLMì´ ìƒì„±í•œ ì´ˆì•ˆì„ ìŠ¤ìŠ¤ë¡œ í”¼ë“œë°±í•˜ê³  ìˆ˜ì •í•˜ëŠ” 'Self-Refine' í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ ë°˜ë³µì ìœ¼ë¡œ í–¥ìƒì‹œí‚´.\\n- ì´ ë°©ë²•ì€ ì—¬ëŸ¬ ë²ˆì˜ API í˜¸ì¶œë¡œ ë¹„ìš©ê³¼ ì‹œê°„ì´ ì¦ê°€í•˜ëŠ” ë‹¨ì ì´ ìˆì§€ë§Œ, ë³„ë„ì˜ í›ˆë ¨ ë°ì´í„° ì—†ì´ë„ ëª¨ë¸ì˜ ë‚´ì¬ëœ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì„.\", 'link': None}, 'annotations': {'bold': False, 'italic': False, 'strikethrough': False, 'underline': False, 'code': False, 'color': 'default'}, 'plain_text': \"- LLMì´ ìƒì„±í•œ ì´ˆì•ˆì„ ìŠ¤ìŠ¤ë¡œ í”¼ë“œë°±í•˜ê³  ìˆ˜ì •í•˜ëŠ” 'Self-Refine' í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ ë°˜ë³µì ìœ¼ë¡œ í–¥ìƒì‹œí‚´.\\n- ì´ ë°©ë²•ì€ ì—¬ëŸ¬ ë²ˆì˜ API í˜¸ì¶œë¡œ ë¹„ìš©ê³¼ ì‹œê°„ì´ ì¦ê°€í•˜ëŠ” ë‹¨ì ì´ ìˆì§€ë§Œ, ë³„ë„ì˜ í›ˆë ¨ ë°ì´í„° ì—†ì´ë„ ëª¨ë¸ì˜ ë‚´ì¬ëœ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì„.\", 'href': None}]}, 'End': {'id': 'bK%7Df', 'type': 'date', 'date': None}, 'Last edited time': {'id': 'gEAh', 'type': 'last_edited_time', 'last_edited_time': '2025-07-06T11:39:00.000Z'}, 'Tag': {'id': 'uOoM', 'type': 'multi_select', 'multi_select': [{'id': '3ffa3050-7bde-426e-ae3c-056680ea673b', 'name': 'Large Language Model', 'color': 'orange'}, {'id': '73a73b42-9307-4534-a5af-66ddffe6a3a1', 'name': 'prompt engineering', 'color': 'gray'}, {'id': '91e565b7-7431-4e02-9670-ecc1377f8f44', 'name': 'In-Context Learning', 'color': 'pink'}, {'id': '83303498-f750-484a-bee6-81157bd97c3a', 'name': 'Iterative Refinement', 'color': 'orange'}]}, 'Title': {'id': 'title', 'type': 'title', 'title': [{'type': 'text', 'text': {'content': 'Self-Refine: Iterative Refinement with Self-Feedback', 'link': None}, 'annotations': {'bold': False, 'italic': False, 'strikethrough': False, 'underline': False, 'code': False, 'color': 'default'}, 'plain_text': 'Self-Refine: Iterative Refinement with Self-Feedback', 'href': None}]}, 'Finish': {'id': 'fef1e3a8-9405-4839-a737-9e8c579f9d08', 'type': 'checkbox', 'checkbox': False}}, 'url': 'https://www.notion.so/Self-Refine-Iterative-Refinement-with-Self-Feedback-2283a61e46e5815bbebac967e29ac7da', 'public_url': None, 'request_id': 'c55722ba-ff19-4b85-836a-888c353bb545'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def parse_notion_json(output):\n",
    "    title = output.title\n",
    "    year = output.year\n",
    "    citation = output.citation\n",
    "    summary = output.short_summary\n",
    "    tags = output.tags\n",
    "    content = output.content\n",
    "    paper_url = output.paper_url\n",
    "\n",
    "    new_page_json = {\n",
    "        \"parent\": {\"database_id\": DATABASE_ID},\n",
    "        \"properties\": {\n",
    "            \"Title\": {  # âœ… Titleì€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨\n",
    "                \"title\": [{\"text\": {\"content\": title}}]\n",
    "            },\n",
    "            \"Year\": {\"number\": year},  # âœ… ìˆ«ìí˜•\n",
    "            \"Citation\": {\"number\": citation},  # âœ… ìˆ«ìí˜•\n",
    "            \"Summary\": {\"rich_text\": [{\"text\": {\"content\": summary}}]},  # âœ… rich_text\n",
    "            \"Tag\": {\"multi_select\": [{\"name\": tag} for tag in tags]},  # âœ… multi_select\n",
    "            \"Done\": {\"checkbox\": False},  # âœ… ì²´í¬ë°•ìŠ¤\n",
    "            \"URL\": {\"url\": paper_url},  # âœ… URL\n",
    "            \"Finish\": {\"checkbox\": False},  # âœ… ì²´í¬ë°•ìŠ¤\n",
    "            # \"End\": {\"date\": {\"start\": \"2025-07-06\"}},  # âœ… ë‚ ì§œ\n",
    "            \"End\": {\"date\": None},  # âœ… ë‚ ì§œ\n",
    "        },\n",
    "        \"children\": [  # âœ… ë³¸ë¬¸ ë‚´ìš© ì¶”ê°€\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"heading_2\",\n",
    "                \"heading_2\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\"type\": \"text\", \"text\": {\"content\": \"Paper Content\"}}\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\"type\": \"text\", \"text\": {\"content\": content_item}}\n",
    "                        for content_item in content\n",
    "                    ]\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return new_page_json\n",
    "\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥\n",
    "NOTION_API_KEY = os.getenv(\"NOTION_API_KEY\")  # ë…¸ì…˜ Integration API í‚¤\n",
    "DATABASE_ID = os.getenv(\"PAPER_DATABASE_ID\")  # ë°ì´í„°ë² ì´ìŠ¤ ID\n",
    "NOTION_VERSION = \"2022-06-28\"\n",
    "\n",
    "\n",
    "# .env ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ì²´í¬\n",
    "if not NOTION_API_KEY or not DATABASE_ID:\n",
    "    raise ValueError(\n",
    "        \"âŒ NOTION_API_KEY ë˜ëŠ” PAPER_DATABASE_ID í™˜ê²½ë³€ìˆ˜ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    )\n",
    "\n",
    "new_page_json = parse_notion_json(output)\n",
    "\n",
    "# API ìš”ì²­\n",
    "response = requests.post(\n",
    "    \"https://api.notion.com/v1/pages\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {NOTION_API_KEY}\",\n",
    "        \"Notion-Version\": NOTION_VERSION,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    },\n",
    "    json=new_page_json,\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "if response.status_code in [200, 201]:\n",
    "    print(\"âœ… í˜ì´ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(\"âŒ ì˜¤ë¥˜ ë°œìƒ:\", response.status_code)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6931c4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c726a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
